{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitmystuff/PydanticAI/blob/main/GROQ_PydanticAI_and_Decorator_Tools_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GROQ PydanticAI and Decorators"
      ],
      "metadata": {
        "id": "S-TVVk-yuM8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install pydantic-ai logfire nest_asyncio devtools"
      ],
      "metadata": {
        "collapsed": true,
        "id": "B2J4egGnuLen"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pydantic-AI is a library that aims to integrate Pydantic's data validation capabilities with AI models, especially large language models (LLMs). This integration allows developers to define structured data models and use LLMs to generate or validate data according to those models."
      ],
      "metadata": {
        "id": "xs1fgV0_saQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from pydantic import BaseModel\n",
        "# from pydantic_ai import Agent, ModelRetry, RunContext\n",
        "# from pydantic_ai.models.groq import GroqModel\n",
        "# from google.colab import userdata\n",
        "# import nest_asyncio\n",
        "# import logfire\n",
        "# logfire.configure(send_to_logfire='if-token-present')\n",
        "\n",
        "# nest_asyncio.apply()\n",
        "# api_key = userdata.get('GROQ_API_KEY')\n",
        "\n",
        "# model = GroqModel('llama-3.3-70b-versatile', api_key=api_key)\n",
        "# agent = Agent(\n",
        "#     model,\n",
        "#     retries=1\n",
        "# )"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "7Hhq65cfsaQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class User(BaseModel):\n",
        "#     name: str\n",
        "#     age: int\n",
        "#     address: str\n",
        "\n",
        "# @agent.system_prompt\n",
        "# async def get_system_prompt(self) -> str:\n",
        "#   return \"\"\"\n",
        "#         You will extract user information from the provided text.\n",
        "#         Return the data as a valid JSON object based on the User model.\n",
        "#         \"\"\"\n",
        "\n",
        "# @agent.tool\n",
        "# def generate_user(ctx: RunContext[User], prompt: str) -> User:\n",
        "#     \"\"\"Generates a user based on a prompt.\"\"\"\n",
        "#     return prompt"
      ],
      "metadata": {
        "id": "2VhARYldQowe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = \"A user named Alice, 30 years old, 1234 Wonderland\"\n",
        "# alice = agent.run_sync(prompt)\n",
        "# print(alice.data)"
      ],
      "metadata": {
        "id": "BOCm-_UJJRyf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add another user - the queen"
      ],
      "metadata": {
        "id": "0cgVa0gXYhAa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add Sentiment class and use it"
      ],
      "metadata": {
        "id": "h03cQVBuGw7m"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alice was very clever"
      ],
      "metadata": {
        "id": "3dWvksAJE9m5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the queen was foul-tempered"
      ],
      "metadata": {
        "id": "ZXBL4ZxoEunQ"
      },
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}